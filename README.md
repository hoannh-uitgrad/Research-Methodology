
# NghiÃªn cá»©u vÃ  ÄÃ¡nh giÃ¡ hiá»‡u nÄƒng mÃ´ hÃ¬nh RT-DETR trong bÃ i toÃ¡n PhÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng thá»i gian thá»±c

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)](https://pytorch.org/)
[![Ultralytics](https://img.shields.io/badge/Ultralytics-YOLO-green)](https://github.com/ultralytics/ultralytics)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **Äá» cÆ°Æ¡ng mÃ´n há»c: PhÆ°Æ¡ng phÃ¡p nghiÃªn cá»©u khoa há»c (CS2205.SEP2025)** > **Há»c viÃªn:** Nguyá»…n Huy HoÃ n  
> **MSSV:** 250101022  
> **TrÆ°á»ng:** Äáº¡i há»c CÃ´ng nghá»‡ ThÃ´ng tin (UIT) - ÄHQG TP.HCM

---

## ğŸ“– Giá»›i thiá»‡u (Introduction)

Dá»± Ã¡n nÃ y táº­p trung nghiÃªn cá»©u, tÃ¡i hiá»‡n vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh **RT-DETR (Real-Time Detection Transformer)** - mÃ´ hÃ¬nh Transformer Ä‘áº§u tiÃªn Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u nÄƒng thá»i gian thá»±c trong bÃ i toÃ¡n phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng.

Má»¥c tiÃªu chÃ­nh lÃ  so sÃ¡nh RT-DETR vá»›i cÃ¡c mÃ´ hÃ¬nh **YOLOv8** (State-of-the-Art hiá»‡n táº¡i) Ä‘á»ƒ chá»©ng minh hiá»‡u quáº£ cá»§a viá»‡c loáº¡i bá» thuáº­t toÃ¡n háº­u xá»­ lÃ½ **NMS (Non-Maximum Suppression)**, tá»« Ä‘Ã³ giáº£i quyáº¿t váº¥n Ä‘á» Ä‘á»™ trá»… biáº¿n thiÃªn vÃ  tá»‘i Æ°u hÃ³a quy trÃ¬nh End-to-End.

---

## ğŸš€ TÃ­nh nÄƒng ná»•i báº­t (Key Features)

* **Real-time End-to-End Object Detection:** KhÃ´ng cáº§n NMS, dá»± Ä‘oÃ¡n trá»±c tiáº¿p táº­p há»£p Ä‘á»‘i tÆ°á»£ng.
* **Efficient Hybrid Encoder:** Kiáº¿n trÃºc lai káº¿t há»£p AIFI (Attention) vÃ  CCFF (CNN) giÃºp tá»‘i Æ°u hÃ³a tá»‘c Ä‘á»™ vÃ  Ä‘á»™ chÃ­nh xÃ¡c.
* **Uncertainty-minimal Query Selection:** CÆ¡ cháº¿ chá»n lá»c truy váº¥n thÃ´ng minh dá»±a trÃªn Ä‘á»™ khÃ´ng cháº¯c cháº¯n, cáº£i thiá»‡n kháº£ nÄƒng khá»Ÿi táº¡o Ä‘áº·c trÆ°ng.
* **High Performance:** Äáº¡t tá»‘c Ä‘á»™ vÃ  Ä‘á»™ chÃ­nh xÃ¡c vÆ°á»£t trá»™i so vá»›i YOLOv8 trÃªn cÃ¹ng Ä‘iá»u kiá»‡n pháº§n cá»©ng.

---

## ğŸ› ï¸ Kiáº¿n trÃºc mÃ´ hÃ¬nh (Model Architecture)

MÃ´ hÃ¬nh RT-DETR bao gá»“m 3 thÃ nh pháº§n chÃ­nh:

1.  **Backbone:** Sá»­ dá»¥ng ResNet/HGNet Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng Ä‘a quy mÃ´ $\{S_3, S_4, S_5\}$.
2.  **Efficient Hybrid Encoder:**
    * **AIFI (Intra-scale interaction):** Sá»­ dá»¥ng Self-Attention trÃªn táº§ng $S_5$ Ä‘á»ƒ náº¯m báº¯t ngá»¯ cáº£nh.
    * **CCFF (Cross-scale fusion):** Sá»­ dá»¥ng CNN Ä‘á»ƒ há»£p nháº¥t cÃ¡c táº§ng Ä‘áº·c trÆ°ng $S_3, S_4, S_5$.
3.  **Transformer Decoder:** Thá»±c hiá»‡n dá»± Ä‘oÃ¡n One-to-one vá»›i cÃ¡c truy váº¥n Ä‘á»‘i tÆ°á»£ng (Object Queries).

![RT-DETR Architecture](assets/architecture_overview.png)
*(HÃ¬nh áº£nh minh há»a kiáº¿n trÃºc tá»•ng quan - Figure 4)*

---

## ğŸ“Š Thá»±c nghiá»‡m & Káº¿t quáº£ (Experiments & Results)

### Thiáº¿t láº­p thá»±c nghiá»‡m (Setup)
* **Dataset:** MS COCO val2017.
* **Hardware:** NVIDIA Tesla T4 GPU.
* **Environment:** TensorRT FP16.
* **Baseline:** So sÃ¡nh vá»›i YOLOv5, YOLOv8 (Scale L vÃ  X).

### Káº¿t quáº£ Benchmark (Benchmark Results)

| Model | Backbone | AP (%) | Latency (ms) | FPS | Params (M) |
| :--- | :--- | :---: | :---: | :---: | :---: |
| **YOLOv8-L** | CSP-Darknet | 52.9% | 14.1 | 71 | 43 |
| **RT-DETR-R50** | ResNet-50 | **53.1%** | **9.3** | **108** | 42 |
| | | | | | |
| **YOLOv8-X** | CSP-Darknet | 53.9% | 20.0 | 50 | 68 |
| **RT-DETR-R101** | ResNet-101 | **54.3%** | **13.5** | **74** | 76 |

> **Káº¿t luáº­n:** RT-DETR-R50 vÆ°á»£t trá»™i hÆ¡n YOLOv8-L cáº£ vá» Ä‘á»™ chÃ­nh xÃ¡c (+0.2% AP) vÃ  tá»‘c Ä‘á»™ (+52% FPS) nhá» loáº¡i bá» hoÃ n toÃ n Ä‘á»™ trá»… cá»§a NMS.

---

## ğŸ’» CÃ i Ä‘áº·t & Sá»­ dá»¥ng (Installation & Usage)

### 1. YÃªu cáº§u (Prerequisites)
* Python 3.8+
* PyTorch 2.0+
* CUDA (khuyáº¿n nghá»‹ Ä‘á»ƒ training/inference GPU)

### 2. CÃ i Ä‘áº·t (Installation)
```bash
# Clone repository
git clone [https://github.com/hoannh-uitgrad/Research-Methodology](https://github.com/hoannh-uitgrad/Research-Methodology)
cd Research-Methodology

# Install dependencies
pip install -r requirements.txt
pip install ultralytics  # Hoáº·c cÃ i Ä‘áº·t RT-DETR tá»« source chÃ­nh thá»©c

```

### 3. Huáº¥n luyá»‡n (Training)

```bash
# Training RT-DETR trÃªn táº­p COCO
yolo train model=rtdetr-l.pt data=coco8.yaml epochs=100 imgsz=640

```

### 4. Kiá»ƒm thá»­ (Validation/Inference)

```bash
# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p validation
yolo val model=rtdetr-l.pt data=coco8.yaml

# Cháº¡y dá»± Ä‘oÃ¡n trÃªn video/áº£nh
yolo predict model=rtdetr-l.pt source='path/to/video.mp4' show=True

```

---

## ğŸ¥ video bÃ¡o cÃ¡o

https://youtu.be/qCSqRuyEheQ

---

## ğŸ“š TÃ i liá»‡u tham kháº£o (References)

1. Lv, W., et al. (2024). *DETRs Beat YOLOs on Real-time Object Detection*. CVPR 2024.
2. Jocher, G., et al. (2023). *Ultralytics YOLO*.
3. Carion, N., et al. (2020). *End-to-End Object Detection with Transformers*. ECCV 2020.
4. Zhu, X., et al. (2021). *Deformable DETR: Deformable Transformers for End-to-End Object Detection*. ICLR 2021.

---

## ğŸ“¬ LiÃªn há»‡ (Contact)

**Nguyá»…n Huy HoÃ n**

* ğŸ“§ Email: hoannh.20@grad.uit.edu.vn
* ğŸ›ï¸ University of Information Technology (UIT) - VNU-HCM
* ğŸ”— GitHub: [huyhoanFithcmus](https://github.com/huyhoanFithcmus)

---

*Dá»± Ã¡n nÃ y lÃ  má»™t pháº§n cá»§a mÃ´n há»c PhÆ°Æ¡ng phÃ¡p nghiÃªn cá»©u khoa há»c táº¡i trÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡ ThÃ´ng tin (UIT).*

